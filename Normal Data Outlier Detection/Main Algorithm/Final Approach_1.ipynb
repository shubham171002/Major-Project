{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2fb1afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c9a6520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import shapiro\n",
    "from scipy.stats import anderson\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pyclustertend import hopkins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fddd122",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from pyod.models.mcd import MCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ede6f047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.random.normal(size=(10000,2))\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "23889378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# anderson(data).statistic < anderson(data).critical_values[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d0e2d8",
   "metadata": {},
   "source": [
    "### Experimets regarding Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ca59080c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "x_sc = sc.fit_transform(data.reshape(-1,1))\n",
    "count = 0\n",
    "for i in x_sc:\n",
    "    if i > 3 or i < -3:\n",
    "        count += 1\n",
    "count\n",
    "x_sc.flatten().ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d7497c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean = data.mean()\n",
    "# std = data.std()\n",
    "# x_sc = np.array([(i-mean)/std for i in data])\n",
    "# count = 0\n",
    "# for i in x_sc:\n",
    "#     if i > 3 or i < -3:\n",
    "#         count += 1\n",
    "# count\n",
    "\n",
    "filtered_data\n",
    "# count = 0\n",
    "# for i in filtered_data:\n",
    "#     if i > 3 or i < -3:\n",
    "#         count += 1\n",
    "# count\n",
    "\n",
    "len(data) - len(filtered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0b815187",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered_data = x_sc[(-3 <= x_sc) & (x_sc <= 3)]\n",
    "outliers = x_sc[(x_sc > 3) | (x_sc < -3)]\n",
    "# outliers\n",
    "df = pd.DataFrame(data)\n",
    "# data - filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "722ffbb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KMeans(n_clusters=2,random_state=0,n_init='auto')\n",
    "model.fit(filtered_data.reshape(-1,1))\n",
    "labels = model.labels_\n",
    "print(len(labels))\n",
    "count = 0\n",
    "# #Labelling clusters and outliers\n",
    "# df['label'] = -1\n",
    "# # df.loc[df.index.isin([i[1] for i in enumerate(filtered_data)]), 'label'] = labels \n",
    "\n",
    "# # unique_indices = \n",
    "# df.loc[np.unique(np.where((-3 <= x_sc) & (x_sc <= 3))[0]), 'label'] = labels        \n",
    "# df['label'].value_counts()\n",
    "all_labels = -1 * np.ones_like(x_sc.flatten())  # Initialize all as outliers\n",
    "# filtered_indices = np.unique(np.where((-3 <= x_sc) & (x_sc <= 3))[0])\n",
    "all_labels[np.unique(np.where((-3 <= x_sc) & (x_sc <= 3))[0])] = labels\n",
    "for i in all_labels:\n",
    "    if i == -1:\n",
    "        count +=1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd0441b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.normal(size=(10000,2))\n",
    "df = pd.DataFrame(data)\n",
    "model = IsolationForest(contamination=0.0026)\n",
    "df['anomaly'] = model.fit_predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec9289db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(df.anomaly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67ae1e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "anomaly\n",
       " 1    9974\n",
       "-1      26\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.anomaly.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27242da",
   "metadata": {},
   "source": [
    "### Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "218e706b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_KMeans(data,contamination=0.05,clustering=True):\n",
    "    data = np.array(data)\n",
    "    data_dimension = data.ndim\n",
    "    if data_dimension == 1:\n",
    "        # Single Dimensional Data\n",
    "        if anderson(data).statistic < anderson(data).critical_values[2]:\n",
    "            # data_distribution = 'normal'\n",
    "            sc = StandardScaler()\n",
    "            x_sc = sc.fit_transform(data.reshape(-1,1))\n",
    "            \n",
    "            if clustering == False:\n",
    "                outliers = x_sc[(x_sc > 3) | (x_sc < -3)]\n",
    "                labels = np.ones(len(data))\n",
    "                outlier_mask = np.isin(data, outliers)\n",
    "                labels[outlier_mask] = -1\n",
    "                return labels\n",
    "            else:\n",
    "                filtered_data = x_sc[(-3 <= x_sc) & (x_sc <= 3)]\n",
    "                hopkins_stats = hopkins(filtered_data,len(filtered_data)//10)\n",
    "                if hopkins_stats < 0.5:\n",
    "                    return ('Data can not be clustered')\n",
    "                else:\n",
    "                    k_values = range(2, 11)\n",
    "                    models = [KMeans(n_clusters=k, random_state=42,n_init='auto').fit(filtered_data.reshape(-1,1)) for k in k_values]\n",
    "                    labels = [model.labels_ for model in models]\n",
    "                    sil_score = [silhouette_score(data,label) for label in labels]\n",
    "                    optimal_k = k_values[np.argmax(sil_score)]\n",
    "                    \n",
    "                    model = KMeans(n_clusters=optimal_k,random_state=0,n_init='auto')\n",
    "                    model.fit(filtered_data.reshape(-1,1))\n",
    "                    labels = model.labels_\n",
    "                    cluster_label = -1 * np.ones_like(x_sc.flatten())\n",
    "                    cluster_label[np.unique(np.where((-3 <= x_sc) & (x_sc <= 3))[0])] = labels\n",
    "                    return cluster_label\n",
    "        \n",
    "        else:\n",
    "            # data_distribution = 'non_normal'\n",
    "            Q1 = np.quantile(data,0.25)\n",
    "            Q3 = np.quantile(data,0.75)\n",
    "            IQR = Q3-Q1\n",
    "            lw = Q1 - 1.5*IQR\n",
    "            rw = Q3 + 1.5*IQR\n",
    "            \n",
    "            if clustering == False:\n",
    "                outliers = data[(data > rw) | (data < lw)]\n",
    "                labels = np.ones(len(data))\n",
    "                outlier_mask = np.isin(data, outliers)\n",
    "                labels[outlier_mask] = -1\n",
    "                return labels\n",
    "            else:\n",
    "                filtered_data = data[(lw <= data) & (data <= rw)]\n",
    "                hopkins_stats = hopkins(filtered_data,len(filtered_data)//10)\n",
    "                if hopkins_stats < 0.5:\n",
    "                    return ('Data can not be clustered')\n",
    "                else:\n",
    "                    k_values = range(2, 11)\n",
    "                    models = [KMeans(n_clusters=k, random_state=42,n_init='auto').fit(filtered_data.reshape(-1,1)) for k in k_values]\n",
    "                    labels = [model.labels_ for model in models]\n",
    "                    sil_score = [silhouette_score(data,label) for label in labels]\n",
    "                    optimal_k = k_values[np.argmax(sil_score)]\n",
    "                    \n",
    "                    model = KMeans(n_clusters=optimal_k,random_state=0,n_init='auto')\n",
    "                    model.fit(filtered_data.reshape(-1,1))\n",
    "                    labels = model.labels_\n",
    "                    cluster_label = -1 * np.ones_like(x_sc.flatten())\n",
    "                    cluster_label[np.unique(np.where((-3 <= x_sc) & (x_sc <= 3))[0])] = labels\n",
    "                    return cluster_label\n",
    "    else:\n",
    "        # Multi Dimensional Data\n",
    "        if shapiro(data)[1] < 0.05:\n",
    "            #data_distribution = 'non_normal'\n",
    "            df = pd.DataFrame(data)\n",
    "            model = IsolationForest(contamination=contamination)\n",
    "            df['anomaly'] = model.fit_predict(df)\n",
    "            \n",
    "            if clustering == False:\n",
    "                return np.array(df['anomaly'])\n",
    "            else:\n",
    "                fil = df['anomaly'] == -1\n",
    "                filtered_data = df.loc[fil].iloc[:,:-1].values\n",
    "                hopkins_stats = hopkins(filtered_data,len(filtered_data)//10)\n",
    "                if hopkins_stats < 0.5:\n",
    "                    return ('Data can not be clustered')\n",
    "                else:\n",
    "                    k_values = range(2, 11)\n",
    "                    models = [KMeans(n_clusters=k, random_state=42,n_init='auto').fit(filtered_data) for k in k_values]\n",
    "                    labels = [model.labels_ for model in models]\n",
    "                    sil_score = [silhouette_score(data,label) for label in labels]\n",
    "                    optimal_k = k_values[np.argmax(sil_score)]\n",
    "                    \n",
    "                    model = KMeans(n_clusters=optimal_k,random_state=42,n_init='auto')\n",
    "                    model.fit(filtered_data)\n",
    "                    labels = model.labels_\n",
    "                    df.loc[df['anomaly'] == -1,'label'] = -1\n",
    "                    df.loc[df['anomaly'] == 1,'label'] = labels\n",
    "                    return np.array(df['label'])\n",
    "                \n",
    "        else:\n",
    "            # data_distribution = 'normal'\n",
    "            df = pd.DataFrame(data)\n",
    "            model = MCD(contamination=contamination)\n",
    "            model.fit(data)\n",
    "            df['anomaly'] = model.predict(data)\n",
    "            df['anomaly'] = df['anomaly'].replace({0: 1, 1: -1})\n",
    "\n",
    "            if clustering == False:\n",
    "                return np.array(df['anomaly'])\n",
    "            else:\n",
    "                fil = df['anomaly'] == -1\n",
    "                filtered_data = df.loc[fil].iloc[:,:-1].values\n",
    "                hopkins_stats = hopkins(filtered_data,len(filtered_data)//10)\n",
    "                if hopkins_stats < 0.5:\n",
    "                    return ('Data can not be clustered')\n",
    "                else:\n",
    "                    k_values = range(2, 11)\n",
    "                    models = [KMeans(n_clusters=k, random_state=42,n_init='auto').fit(filtered_data) for k in k_values]\n",
    "                    labels = [model.labels_ for model in models]\n",
    "                    sil_score = [silhouette_score(data,label) for label in labels]\n",
    "                    optimal_k = k_values[np.argmax(sil_score)]\n",
    "                    \n",
    "                    model = KMeans(n_clusters=optimal_k,random_state=42,n_init='auto')\n",
    "                    model.fit(filtered_data)\n",
    "                    labels = model.labels_\n",
    "                    df.loc[df['anomaly'] == -1,'label'] = -1\n",
    "                    df.loc[df['anomaly'] == 1,'label'] = labels\n",
    "                    return np.array(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ed3c9b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = outlier_KMeans(data,k=2)\n",
    "# len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0f94288d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5f13b3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.normal(25,5,size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "124581cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "x_sc = sc.fit_transform(data.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7b87ff9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for i in data:\n",
    "    if i < -3 or i > 3:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0a18b7bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for i in x_sc:\n",
    "    if i < -3 or i > 3:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be8158b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
